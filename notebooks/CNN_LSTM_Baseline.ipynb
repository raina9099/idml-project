{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ayQIkU7Em2v"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Oct  5 19:26:29 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           On  | 00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   39C    P0              25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m734.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m955.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from torch) (3.16.1)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m249.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m861.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from torchvision) (2.1.2)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 pillow-10.4.0 sympy-1.13.3 torch-2.4.1 torchvision-0.19.1 triton-3.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoWvbWIZTPUv",
        "outputId": "31dee983-4e51-4ca5-95fb-01e5ac1cd915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchsummaryX\n",
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWEgeL-KIZtq",
        "outputId": "d6bba5be-2cf2-4f6a-c298-f559957f55df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from datasets) (24.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.32.2\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting fsspec[http]<=2024.6.1,>=2023.1.0\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.17\n",
            "  Downloading numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.66.3\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.22.0\n",
            "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting attrs>=17.3.0\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Collecting async-timeout<5.0,>=4.0\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting yarl<2.0,>=1.12.0\n",
            "  Downloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (447 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.9/447.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m771.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/ubuntu/odml-project/odml-venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, pyyaml, numpy, multidict, idna, fsspec, frozenlist, filelock, dill, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, pyarrow, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
            "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.9 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.3.2 datasets-3.0.1 dill-0.3.8 filelock-3.16.1 frozenlist-1.4.1 fsspec-2024.6.1 huggingface-hub-0.25.1 idna-3.10 multidict-6.1.0 multiprocess-0.70.16 numpy-2.1.2 pandas-2.2.3 pyarrow-17.0.0 pytz-2024.2 pyyaml-6.0.2 requests-2.32.3 tqdm-4.66.5 tzdata-2024.2 urllib3-2.2.3 xxhash-3.5.0 yarl-1.13.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting editdistance\n",
            "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: editdistance\n",
            "Successfully installed editdistance-0.8.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install editdistance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rsitW6SEp-9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZGf0Jj1CRtr",
        "outputId": "57e34a36-2c4b-4445-a388-1df3e1031abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset\n",
        "import editdistance\n",
        "# from torchsummary import summary\n",
        "from torchinfo import summary\n",
        "import torch.nn.functional as F\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MccBiCSzI3DD"
      },
      "source": [
        "# Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fJj4IjrhI46X"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"lr\"         : 0.002,\n",
        "    \"epochs\"     : 20,\n",
        "    \"batch_size\" : 64,\n",
        "    'img_height': 128,\n",
        "    'img_width': 1000,\n",
        "    'lstm_num_layers': 4,\n",
        "    'lstm_hidden_size': 256,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssdvA7QULest"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmfEAhc-ut0p",
        "outputId": "cb7ee024-ab9e-4f42-a665-92582a25555b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1022"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NtCFs-fLCRwA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 6482/6482 [00:00<00:00, 17249.75 examples/s]\n",
            "Generating validation split: 100%|██████████| 976/976 [00:00<00:00, 19535.95 examples/s]\n",
            "Generating test split: 100%|██████████| 2915/2915 [00:00<00:00, 18520.18 examples/s]\n"
          ]
        }
      ],
      "source": [
        "IMAGE_HEIGHT = config['img_height']\n",
        "IMAGE_WIDTH = config['img_width']\n",
        "BATCH_SIZE = config['batch_size']\n",
        "NUM_EPOCHS = config['epochs']\n",
        "LEARNING_RATE = config['lr']\n",
        "\n",
        "# Load the dataset from Hugging Face\n",
        "dataset = load_dataset(\"Teklia/IAM-line\")\n",
        "\n",
        "# Define transforms\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# Create a character-to-index mapping\n",
        "chars = set(''.join(dataset['train']['text']))\n",
        "char_to_index = {char: idx + 1 for idx, char in enumerate(sorted(chars))}\n",
        "char_to_index['<PAD>'] = 0\n",
        "index_to_char = {idx: char for char, idx in char_to_index.items()}\n",
        "vocab_size = len(char_to_index)\n",
        "\n",
        "# Tokenizer functions\n",
        "def tokenize(text):\n",
        "    return [char_to_index[char] for char in text]\n",
        "\n",
        "def detokenize(indices):\n",
        "    return ''.join([index_to_char[idx] for idx in indices if idx != 0])\n",
        "\n",
        "# Dataset class\n",
        "class IAMLinesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, hf_dataset, split, transform=None):\n",
        "        self.dataset = hf_dataset[split]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        image = item['image']\n",
        "        text = item['text']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # print(\"Before tokenization: \", len(text), \"text: \", text)\n",
        "        target = torch.LongTensor(tokenize(text))\n",
        "\n",
        "        return image, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    images = torch.stack(images)\n",
        "\n",
        "    # Pad sequences\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Create mask for actual lengths\n",
        "    target_lengths = torch.LongTensor([len(t) for t in targets])\n",
        "\n",
        "    # return images, targets, target_lengths\n",
        "    return images, targets\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = IAMLinesDataset(dataset, 'train', transform)\n",
        "val_dataset = IAMLinesDataset(dataset, 'validation', transform)\n",
        "test_dataset = IAMLinesDataset(dataset, 'test', transform)\n",
        "\n",
        "# Create dataloaders with the custom collate_fn\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYjMKwpuLOZ4",
        "outputId": "1539f82d-e2b7-4ae9-aac2-e1617c97ed70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in train set: 6482\n",
            "Number of samples in test set: 2915\n",
            "Number of samples in val set: 976\n",
            "Batch size: 64\n",
            "Num batches in train_loader: 102\n",
            "Num batches in test_loader: 46\n",
            "Num batches in val_loader: 16\n",
            "Shape of 23-th item in train set:\n",
            "Image: torch.Size([1, 128, 1000]), Label: torch.Size([39])\n",
            "Shape of 23-th item in a batch of train loader:\n",
            "Shape of entire batch of images: torch.Size([64, 1, 128, 1000])\n",
            "Shape of entire batch of labels: torch.Size([64, 70])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of samples in train set: {len(train_dataset)}\")\n",
        "print(f\"Number of samples in test set: {len(test_dataset)}\")\n",
        "print(f\"Number of samples in val set: {len(val_dataset)}\")\n",
        "\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Num batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Num batches in test_loader: {len(test_loader)}\")\n",
        "print(f\"Num batches in val_loader: {len(val_loader)}\")\n",
        "\n",
        "i=23\n",
        "print(f\"Shape of {i}-th item in train set:\")\n",
        "print(f\"Image: {train_dataset[i][0].shape}, Label: {train_dataset[i][1].shape}\")\n",
        "\n",
        "print(f\"Shape of {i}-th item in a batch of train loader:\")\n",
        "x = next(iter(train_loader)) # (batch of 32 images, batch of 32 labels)\n",
        "print(f\"Shape of entire batch of images: {x[0].shape}\")\n",
        "print(f\"Shape of entire batch of labels: {x[1].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5L6i68CLhpE"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "i9sVZKEtOzqz"
      },
      "outputs": [],
      "source": [
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, num_layers, num_classes):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3, 3), stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),  # Reduce height and width by 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))  # Further reduce height and width by 2\n",
        "        )\n",
        "\n",
        "        # LSTM part\n",
        "        # LSTM input size = out_channels of last Conv2d * img height after all conv layers i.e input_img_width / (2**num_maxpool_layers)\n",
        "        self.lstm = nn.LSTM(input_size=128*32, hidden_size=hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
        "        # self.lstm = nn.LSTM(input_size=512*8, hidden_size=hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
        "        nn.BatchNorm2d(2 * hidden_size)\n",
        "        self.fc = nn.Linear(2 * hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input x has shape (batch_size, channels, height, width)\n",
        "        # print(\"input: \", x.shape) # (32, 1, 128, 1000]\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Pass through CNN (output will have shape (batch_size, 128, 32, 250))\n",
        "        out = self.cnn(x)\n",
        "        # print(\"cnn output: \", out.shape) # (32, 128, 32, 250)\n",
        "        # Reshape output from CNN to prepare it for LSTM\n",
        "        # New shape: (batch_size, 250, 128*32) where 250 is the reduced width (seq_len)\n",
        "        # print(\"before reshape output: \", out.shape) # (32, 128, 32, 250)\n",
        "        batch_size, cnn_output_channels, cnn_output_height, cnn_output_width = out.shape #(32, 128, 32, 250)\n",
        "        out = out.reshape(batch_size, cnn_output_width, cnn_output_channels * cnn_output_height)\n",
        "        # print(\"after reshape output: \", out.shape)\n",
        "\n",
        "        # Pass through LSTM (input shape (batch_size, seq_len=250, input_size=128*32))\n",
        "        out, _ = self.lstm(out)\n",
        "        # print(\"lstm output: \", out.shape)\n",
        "\n",
        "        out = self.fc(out)\n",
        "        # print(\"fc output: \", out.shape)\n",
        "\n",
        "        out = F.log_softmax(out, dim=2)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bdjQgVKEbcy",
        "outputId": "9101540e-b12c-4a8e-c88f-7d810348391a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CNN_LSTM                                 [1, 250, 80]              --\n",
              "├─Sequential: 1-1                        [1, 128, 32, 250]         --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 128, 1000]        640\n",
              "│    └─BatchNorm2d: 2-2                  [1, 64, 128, 1000]        128\n",
              "│    └─ReLU: 2-3                         [1, 64, 128, 1000]        --\n",
              "│    └─MaxPool2d: 2-4                    [1, 64, 64, 500]          --\n",
              "│    └─Conv2d: 2-5                       [1, 128, 64, 500]         73,856\n",
              "│    └─BatchNorm2d: 2-6                  [1, 128, 64, 500]         256\n",
              "│    └─ReLU: 2-7                         [1, 128, 64, 500]         --\n",
              "│    └─MaxPool2d: 2-8                    [1, 128, 32, 250]         --\n",
              "├─LSTM: 1-2                              [1, 250, 512]             13,647,872\n",
              "├─Linear: 1-3                            [1, 250, 80]              41,040\n",
              "==========================================================================================\n",
              "Total params: 13,763,792\n",
              "Trainable params: 13,763,792\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 5.86\n",
              "==========================================================================================\n",
              "Input size (MB): 0.51\n",
              "Forward/backward pass size (MB): 197.79\n",
              "Params size (MB): 55.06\n",
              "Estimated Total Size (MB): 253.36\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNN_LSTM(hidden_size=config['lstm_hidden_size'], num_layers=config['lstm_num_layers'], num_classes=vocab_size).to(device)\n",
        "batch_size=1\n",
        "input_channels=1\n",
        "img_height=128\n",
        "img_width=1000\n",
        "summary(model, (batch_size, input_channels, img_height, img_width))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2M-RKnlRoXb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "grLxLMJVDHjO"
      },
      "outputs": [],
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "criterion = nn.CTCLoss(blank=0)\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr= config['lr'], weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "scaler = torch.amp.GradScaler('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IpYUNZp4RjBa"
      },
      "outputs": [],
      "source": [
        "def ctc_decode_tensor(predicted_indices):\n",
        "    if not isinstance(predicted_indices, torch.Tensor):\n",
        "        predicted_indices = torch.tensor(predicted_indices)\n",
        "\n",
        "    batch_size, seq_length = predicted_indices.shape\n",
        "    non_blank_mask = predicted_indices != 0\n",
        "    diff_mask = torch.cat([torch.ones(batch_size, 1, dtype=torch.bool, device=predicted_indices.device),\n",
        "                           predicted_indices[:, 1:] != predicted_indices[:, :-1]], dim=1)\n",
        "    valid_mask = non_blank_mask & diff_mask\n",
        "    decoded = predicted_indices * valid_mask.long()\n",
        "    decoded_list = [seq[seq != 0].tolist() for seq in decoded]\n",
        "\n",
        "    return decoded_list\n",
        "\n",
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    metric  = checkpoint[metric]\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    total_distance = 0\n",
        "    total_length = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get the predicted indices\n",
        "            predicted_indices = torch.argmax(outputs, dim=2) #(batchsize, seqlen)\n",
        "            decoded_predictions = ctc_decode_tensor(predicted_indices)\n",
        "\n",
        "            # Convert predictions and targets to strings\n",
        "            predicted_strings = [''.join([index_to_char[idx.item() if isinstance(idx, torch.Tensor) else idx] for idx in pred if idx != 0]) for pred in decoded_predictions]\n",
        "            target_strings = [''.join([index_to_char[idx.item() if isinstance(idx, torch.Tensor) else idx] for idx in tgt if idx != 0]) for tgt in targets]\n",
        "\n",
        "            # Compute edit distance\n",
        "            for pred, tgt in zip(predicted_strings, target_strings):\n",
        "                # print(\"Predicted string: \", pred)\n",
        "                # print(\"Target string: \", tgt)\n",
        "                distance = editdistance.eval(pred, tgt)\n",
        "                # print(\"Distance: \", distance)\n",
        "                total_distance += distance\n",
        "                total_length += len(tgt)\n",
        "\n",
        "            del images, targets, predicted_indices, decoded_predictions, predicted_strings, target_strings, outputs, distance\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Compute Character Error Rate (CER)\n",
        "    cer = total_distance / total_length\n",
        "    return cer\n",
        "\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, learning_rate, device):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            # print(\"targets: \", targets.shape) #(32, 60)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # with torch.cuda.amp.autocast():\n",
        "            with torch.amp.autocast('cuda'):\n",
        "            # Forward pass\n",
        "              outputs = model(images)\n",
        "              # print(\"Forward output: \", outputs.shape) #(32, 250, 80)\n",
        "\n",
        "              # Prepare CTC loss inputs\n",
        "              input_lengths = torch.full(size=(outputs.size(0),), fill_value=outputs.size(1), dtype=torch.long)\n",
        "              # print(\"input_lengths: \", input_lengths.shape) #(32)\n",
        "              target_lengths = torch.sum(targets != 0, dim=1)\n",
        "              # print(\"target_lengths: \", target_lengths.shape) #(32)\n",
        "\n",
        "              # Compute loss\n",
        "              loss = criterion(outputs.transpose(0, 1), targets, input_lengths, target_lengths)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            # loss.backward()\n",
        "            # optimizer.step()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            del images, targets, outputs, input_lengths, target_lengths, loss\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (batch_idx + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "            batch_bar.update()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'\\nEpoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # Validate after each epoch\n",
        "        val_cer = evaluate(model, val_loader, device)\n",
        "        print(f'Validation CER: {val_cer:.4f}')\n",
        "\n",
        "        if epoch+1 % 10 == 0:\n",
        "            save_model(model, optimizer, scheduler, ['valid_CER', val_cer], epoch, f\"cnn-lstm-model_epoch_{epoch+1}.pth\")\n",
        "\n",
        "        batch_bar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUykXoWTRsEL",
        "outputId": "713e31a5-9d0a-4b19-d907-0f664abdb20d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: 100%|██████████| 102/102 [01:08<00:00,  1.78it/s, loss=4.2282, lr=0.002000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/20], Average Loss: 4.2282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation CER: 1.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   5%|▍         | 5/102 [00:03<01:04,  1.50it/s, loss=3.2479, lr=0.002000]"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=NUM_EPOCHS, learning_rate=LEARNING_RATE, device=device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3ayQIkU7Em2v",
        "0rsitW6SEp-9",
        "ssdvA7QULest",
        "OTJGGiZfu43y"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
